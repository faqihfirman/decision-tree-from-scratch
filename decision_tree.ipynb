{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640debf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ec471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "    'plant_age_days': [90, 60, 80, 50],\n",
    "    'height_cm': [105, 70, 95, 60],\n",
    "    'leaf_color': ['yellow', 'green', 'dark green', 'green'],\n",
    "    'rainfall': ['high', 'medium', 'medium', 'low'],\n",
    "    'soil_moisture': ['medium', 'low', 'medium', 'low'],\n",
    "    'ready': ['yes', 'no', 'yes', 'no'] \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ec9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature       \n",
    "        self.threshold = threshold    \n",
    "        self.left = left              \n",
    "        self.right = right            \n",
    "        self.value = value            \n",
    "\n",
    "\n",
    "class MyDecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "      \n",
    "        dataset = np.column_stack((X, y))\n",
    "        self.root = self._grow_tree(dataset)\n",
    "\n",
    "    def _calculate_entropy(self, y):\n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy\n",
    "\n",
    "    def _information_gain(self, y, y_left, y_right):\n",
    "        weight_left = len(y_left) / len(y)\n",
    "        weight_right = len(y_right) / len(y)\n",
    "        return self._calculate_entropy(y) - (weight_left * self._calculate_entropy(y_left) + weight_right * self._calculate_entropy(y_right))\n",
    "\n",
    "    def _best_split(self, dataset, num_features):\n",
    "        best_gain = -1\n",
    "        split_idx, split_thresh = None, None\n",
    "        \n",
    "        \n",
    "        for feat_idx in range(num_features):\n",
    "            X_column = dataset[:, feat_idx]\n",
    "            unique_values = np.unique(X_column)\n",
    "\n",
    "           \n",
    "            for threshold in unique_values:\n",
    "                \n",
    "                if isinstance(threshold, (int, float, np.number)):\n",
    "                    left_indices = np.where(X_column <= threshold)[0]\n",
    "                    right_indices = np.where(X_column > threshold)[0]\n",
    "                else:\n",
    "                    left_indices = np.where(X_column == threshold)[0]\n",
    "                    right_indices = np.where(X_column != threshold)[0] \n",
    "\n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "\n",
    "                y = dataset[:, -1]\n",
    "                y_left, y_right = y[left_indices], y[right_indices]\n",
    "                \n",
    "                gain = self._information_gain(y, y_left, y_right)\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_thresh = threshold\n",
    "\n",
    "        return split_idx, split_thresh\n",
    "\n",
    "    def _grow_tree(self, dataset, depth=0):\n",
    "        X, y = dataset[:, :-1], dataset[:, -1]\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "    \n",
    "        if n_labels == 1 or depth >= self.max_depth or n_samples < self.min_samples_split:\n",
    "            \n",
    "            vals, counts = np.unique(y, return_counts=True)\n",
    "            most_common = vals[np.argmax(counts)]\n",
    "            return Node(value=most_common)\n",
    "\n",
    "        \n",
    "        best_idx, best_thresh = self._best_split(dataset, n_features)\n",
    "\n",
    "        \n",
    "        if best_idx is None:\n",
    "            vals, counts = np.unique(y, return_counts=True)\n",
    "            most_common = vals[np.argmax(counts)]\n",
    "            return Node(value=most_common)\n",
    "\n",
    "        \n",
    "        if isinstance(best_thresh, (int, float, np.number)):\n",
    "             left_idxs = np.where(X[:, best_idx] <= best_thresh)[0]\n",
    "             right_idxs = np.where(X[:, best_idx] > best_thresh)[0]\n",
    "        else:\n",
    "             left_idxs = np.where(X[:, best_idx] == best_thresh)[0]\n",
    "             right_idxs = np.where(X[:, best_idx] != best_thresh)[0]\n",
    "\n",
    "        left = self._grow_tree(dataset[left_idxs, :], depth + 1)\n",
    "        right = self._grow_tree(dataset[right_idxs, :], depth + 1)\n",
    "        \n",
    "        return Node(best_idx, best_thresh, left, right)\n",
    "\n",
    "    def predict_one(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        feature_val = x[node.feature]\n",
    "        \n",
    "   \n",
    "        go_left = False\n",
    "        if isinstance(node.threshold, (int, float, np.number)):\n",
    "            if feature_val <= node.threshold: go_left = True\n",
    "        else:\n",
    "            if feature_val == node.threshold: go_left = True\n",
    "            \n",
    "        if go_left:\n",
    "            return self.predict_one(x, node.left)\n",
    "        else:\n",
    "            return self.predict_one(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.predict_one(x, self.root) for x in X]\n",
    "    \n",
    "    \n",
    "    def print_tree(self, node=None, indent=\"\"):\n",
    "        if node is None: node = self.root\n",
    "        if node.value is not None:\n",
    "            print(node.value)\n",
    "        else:\n",
    "            col_name = df.columns[node.feature]\n",
    "            condition = f\"{col_name}\"\n",
    "            if isinstance(node.threshold, (int, float, np.number)):\n",
    "                print(f\"{indent}{condition} <= {node.threshold} ?\")\n",
    "            else:\n",
    "                print(f\"{indent}{condition} == {node.threshold} ?\")\n",
    "            \n",
    "            print(f\"{indent} --> True: \", end=\"\")\n",
    "            self.print_tree(node.left, indent + \"  \")\n",
    "            print(f\"{indent} --> False: \", end=\"\")\n",
    "            self.print_tree(node.right, indent + \"  \")\n",
    "\n",
    "\n",
    "X_train = df.iloc[:, :-1].values\n",
    "y_train = df.iloc[:, -1].values\n",
    "\n",
    "model = MyDecisionTree(max_depth=3)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- Struktur Decision Tree ---\")\n",
    "model.print_tree()\n",
    "\n",
    "print(\"\\n--- Prediksi Data Training ---\")\n",
    "predictions = model.predict(X_train)\n",
    "print(\"Asli   :\", y_train)\n",
    "print(\"Prediksi:\", predictions)\n",
    "\n",
    "\n",
    "accuracy = np.sum(y_train == predictions) / len(y_train)\n",
    "print(f\"Akurasi: {accuracy * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sifr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
